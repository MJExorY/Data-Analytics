parameters:
  - name: azureServiceConnection
    type: string
    displayName: 'Azure Service Connection'
  
  - name: environment
    type: string
    displayName: 'Target Environment'
    values:
    - DEV
    - UAT
    - PRD
  
  - name: ms_fabric_workspaces
    type: string
    displayName: 'MS Fabric Workspaces'
  
  - name: tenant_id
    type: string
    displayName: 'Azure Tenant ID'
  
  - name: service_principal_id
    type: string
    displayName: 'Service Principal ID'
  
  - name: dataverse_storage_container
    type: string
    displayName: 'Dataverse Storage Container'
  
  - name: fabric_setup_admin_principal_id
    type: string
    displayName: 'Fabric Setup Admin Principal ID'

variables:
  # Script paths
  - name: scriptBasePath
    value: './dah_devops/pipelines/scripts'
  - name: connectionScript
    value: '$(scriptBasePath)/msfabric_create_connection.sh'
  
  # Connection name
  - name: dataverseConnectionName
    value: 'GFCS_DAH_${{ parameters.environment }}_dataverse_sa002'

steps:
  - checkout: dahFabricWs
    displayName: 'Checkout MS Fabric Workspace Repository'
    clean: true

  - checkout: self
    displayName: 'Checkout DevOps Repository'
    clean: true

  - task: AzureCLI@2
    displayName: 'Install Python Dependencies'
    inputs:
      azureSubscription: ${{ parameters.azureServiceConnection }}
      scriptType: bash
      scriptLocation: inlineScript
      failOnStandardError: true
      inlineScript: |
        set -euo pipefail
        
        echo "##[section]Installing Python dependencies..."
        
        # Upgrade pip first
        echo "##[command]Upgrading pip..."
        python3 -m pip install --upgrade pip
        
        # Install required packages
        echo "##[command]Installing required Python packages..."
        python3 -m pip install \
          azure-storage-file-datalake \
          azure-identity \
          argparse
        
        # Verify installations
        echo "##[section]Verifying installations..."
        python3 -c "import azure.storage.filedatalake; print(f'azure-storage-file-datalake: {azure.storage.filedatalake.__version__}')"
        python3 -c "import azure.identity; print(f'azure-identity: {azure.identity.__version__}')"
        
        echo "##[section]Python dependencies installed successfully"

  - task: AzureCLI@2
    displayName: 'Validate Connection Script'
    inputs:
      azureSubscription: ${{ parameters.azureServiceConnection }}
      scriptType: bash
      scriptLocation: inlineScript
      failOnStandardError: true
      inlineScript: |
        set -euo pipefail
        
        echo "##[section]Validating connection script..."
        
        # Check if connection script exists
        if [ ! -f "$(connectionScript)" ]; then
          echo "##[error]Connection script not found: $(connectionScript)"
          exit 1
        fi
        
        echo "##[command]Found: $(connectionScript)"
        
        # Make script executable
        echo "##[command]Setting executable permissions..."
        chmod +x "$(connectionScript)"
        
        echo "##[section]Script validation completed"

  - task: AzureCLI@2
    displayName: 'Create Dataverse Connection'
    condition: and(succeeded(), not(canceled()))
    inputs:
      azureSubscription: ${{ parameters.azureServiceConnection }}
      scriptType: bash
      scriptLocation: inlineScript
      failOnStandardError: true
      inlineScript: |
        set -euo pipefail
        
        echo "##[section]Creating MS Fabric Dataverse connection..."
        
        echo "##[group]Connection Parameters"
        echo "Connection Name: $(dataverseConnectionName)"
        echo "Environment: ${{ parameters.environment }}"
        echo "Tenant ID: ${{ parameters.tenant_id }}"
        echo "Dataverse Container: ${{ parameters.dataverse_storage_container }}"
        echo "Fabric Admin Principal ID: ${{ parameters.fabric_setup_admin_principal_id }}"
        echo "##[endgroup]"
        
        echo "##[command]Creating Dataverse connection..."
        "$(connectionScript)" \
          --env "${{ parameters.environment }}" \
          --connection-name "$(dataverseConnectionName)" \
          --fabric-setup-admin-principal-key "$(Fabric-IDL-SP-Secret)" \
          --fabric-setup-admin-principal-id "${{ parameters.fabric_setup_admin_principal_id }}" \
          --tenant-id "${{ parameters.tenant_id }}" \
          --dataverse-storage-container "${{ parameters.dataverse_storage_container }}" \
          --action "create_dataverse_conn"
        
        if [ $? -eq 0 ]; then
          echo "##[section]âœ“ Dataverse connection created successfully"
        else
          echo "##[error]Failed to create Dataverse connection"
          exit 1
        fi

# TODO: Lack of Microsoft support for this REST API at the moment: https://gfps-portal.atlassian.net/browse/AGTRAN-16490
  # - task: AzureCLI@2
  #   displayName: 'Modify and Deploy SDL 100_S4_Sales_br_cpl.DataPipeline/pipeline-content.json'
  #   condition: and(succeeded(), not(canceled()))
  #   inputs:
  #     azureSubscription: ${{ parameters.azureServiceConnection }}
  #     scriptType: bash
  #     scriptLocation: inlineScript
  #     inlineScript: |
  #       source_folder_path="./dah_fabric_ws/gfcs_sdl_s4_Sales/100_S4_Sales_br_cpl.DataPipeline/"
  #       ./dah_devops/pipelines/scripts/msfabric_manage_data_pipelines.sh --workspace "GFCS ${{ parameters.environment }} IDL" --env "${{ parameters.environment }}" --data-payload "$(ls ${source_folder_path}/pipeline-content.json)"